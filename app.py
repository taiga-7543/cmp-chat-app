from flask import Flask, request, jsonify, render_template, Response
from google import genai
from google.genai import types
import json
import os
import asyncio
import time
import re
from datetime import datetime
import tempfile

app = Flask(__name__)

# ç’°å¢ƒå¤‰æ•°ã‹ã‚‰è¨­å®šã‚’èª­ã¿è¾¼ã¿
PROJECT_ID = os.environ.get('GOOGLE_CLOUD_PROJECT', 'dotd-development-division')
RAG_CORPUS = os.environ.get('RAG_CORPUS', f'projects/{PROJECT_ID}/locations/us-central1/ragCorpora/3458764513820540928')
GEMINI_MODEL = os.environ.get('GEMINI_MODEL', 'gemini-2.5-flash')

def setup_google_auth():
    """Google Cloudèªè¨¼ã‚’è¨­å®š"""
    # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚­ãƒ¼ã®JSONã‚’èª­ã¿è¾¼ã‚€
    credentials_json = os.environ.get('GOOGLE_APPLICATION_CREDENTIALS_JSON')
    if credentials_json:
        # JSONã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãè¾¼ã‚“ã§èªè¨¼è¨­å®š
        with tempfile.NamedTemporaryFile(mode='w', suffix='.json', delete=False) as f:
            f.write(credentials_json)
            os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = f.name
    
    # æ—¢å­˜ã®GOOGLE_APPLICATION_CREDENTIALSãŒã‚ã‚‹å ´åˆã¯ãã®ã¾ã¾ä½¿ç”¨
    if not os.environ.get('GOOGLE_APPLICATION_CREDENTIALS') and not credentials_json:
        print("Warning: Google Cloudèªè¨¼æƒ…å ±ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")

# èªè¨¼è¨­å®šã‚’åˆæœŸåŒ–
setup_google_auth()

def create_rag_client():
    """RAGã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’ä½œæˆ"""
    client = genai.Client(
        vertexai=True,
        project=PROJECT_ID,
        location="global",
    )
    return client

def extract_date_from_filename(filename):
    """ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰æ—¥ä»˜ã‚’æŠ½å‡ºã™ã‚‹ï¼ˆ_yyyymmddå½¢å¼ã¾ãŸã¯yyyymmddå½¢å¼ï¼‰"""
    if not filename:
        return None
    
    # yyyymmddå½¢å¼ã®æ—¥ä»˜ã‚’æ¤œç´¢ï¼ˆã‚¢ãƒ³ãƒ€ãƒ¼ã‚¹ã‚³ã‚¢ã‚ã‚Šã¾ãŸã¯ãªã—ï¼‰
    # ãƒ‘ã‚¿ãƒ¼ãƒ³1: _yyyymmddå½¢å¼ï¼ˆã‚¢ãƒ³ãƒ€ãƒ¼ã‚¹ã‚³ã‚¢ã‚ã‚Šï¼‰
    # ãƒ‘ã‚¿ãƒ¼ãƒ³2: yyyymmddå½¢å¼ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«åã®å…ˆé ­ã¾ãŸã¯åŒºåˆ‡ã‚Šæ–‡å­—ã®å¾Œï¼‰
    date_patterns = [
        r'_(\d{8})(?:\.|_|$)',  # _yyyymmddå½¢å¼
        r'(?:^|[^\d])(\d{8})(?:[^\d]|$)',  # yyyymmddå½¢å¼ï¼ˆå‰å¾Œã«æ•°å­—ä»¥å¤–ã®æ–‡å­—ï¼‰
    ]
    
    for pattern in date_patterns:
        match = re.search(pattern, filename)
        if match:
            date_str = match.group(1)
            try:
                # æ—¥ä»˜ã®å¦¥å½“æ€§ã‚’ãƒã‚§ãƒƒã‚¯
                date_obj = datetime.strptime(date_str, '%Y%m%d')
                
                # å¦¥å½“ãªæ—¥ä»˜ç¯„å›²ã‚’ãƒã‚§ãƒƒã‚¯ï¼ˆ1900å¹´ã€œ2100å¹´ï¼‰
                if 1900 <= date_obj.year <= 2100:
                    return date_obj
            except ValueError:
                # ç„¡åŠ¹ãªæ—¥ä»˜ã®å ´åˆã¯æ¬¡ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è©¦ã™
                continue
    
    return None

def sort_sources_by_date(sources):
    """å‡ºå…¸æƒ…å ±ã‚’æ—¥ä»˜é †ã«ã‚½ãƒ¼ãƒˆï¼ˆæ–°ã—ã„æ—¥ä»˜ã‚’å„ªå…ˆï¼‰"""
    def get_sort_key(source):
        title = source.get('title', '')
        uri = source.get('uri', '')
        
        # ã‚¿ã‚¤ãƒˆãƒ«ã¨URIã®ä¸¡æ–¹ã‹ã‚‰æ—¥ä»˜ã‚’æŠ½å‡ºã‚’è©¦ã¿ã‚‹
        date_from_title = extract_date_from_filename(title)
        date_from_uri = extract_date_from_filename(uri)
        
        # ã‚ˆã‚Šæ–°ã—ã„æ—¥ä»˜ã‚’ä½¿ç”¨
        extracted_date = None
        if date_from_title and date_from_uri:
            extracted_date = max(date_from_title, date_from_uri)
        elif date_from_title:
            extracted_date = date_from_title
        elif date_from_uri:
            extracted_date = date_from_uri
        
        # æ—¥ä»˜ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯æœ€ã‚‚å¤ã„æ—¥ä»˜ã¨ã—ã¦æ‰±ã†
        if extracted_date is None:
            extracted_date = datetime(1900, 1, 1)
        
        # æ–°ã—ã„æ—¥ä»˜ã‚’å„ªå…ˆã™ã‚‹ãŸã‚ã€æ—¥ä»˜ã‚’é€†é †ã§ã‚½ãƒ¼ãƒˆ
        return (-extracted_date.timestamp(), title.lower())
    
    return sorted(sources, key=get_sort_key)

def convert_grounding_metadata_to_dict(grounding_metadata):
    """GroundingMetadataã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’è¾æ›¸ã«å¤‰æ›ã—ã€æ—¥ä»˜é †ã«ã‚½ãƒ¼ãƒˆ"""
    if not grounding_metadata:
        print("DEBUG: grounding_metadata is None")
        return None
    
    print(f"DEBUG: grounding_metadata type: {type(grounding_metadata)}")
    print(f"DEBUG: grounding_metadata attributes: {dir(grounding_metadata)}")
    
    result = {}
    
    # grounding_chunksã‚’å‡¦ç†
    if hasattr(grounding_metadata, 'grounding_chunks') and grounding_metadata.grounding_chunks:
        print(f"DEBUG: Found {len(grounding_metadata.grounding_chunks)} grounding chunks")
        unsorted_chunks = []
        
        for i, chunk in enumerate(grounding_metadata.grounding_chunks):
            print(f"DEBUG: Processing chunk {i}: {type(chunk)}")
            print(f"DEBUG: Chunk attributes: {dir(chunk)}")
            
            chunk_dict = {}
            
            # retrieved_contextã‹ã‚‰titleã¨uriã‚’å–å¾—
            if hasattr(chunk, 'retrieved_context') and chunk.retrieved_context:
                print(f"DEBUG: Found retrieved_context: {type(chunk.retrieved_context)}")
                retrieved_context = chunk.retrieved_context
                
                # titleã‚’å–å¾—
                if hasattr(retrieved_context, 'title') and retrieved_context.title:
                    chunk_dict['title'] = retrieved_context.title
                    print(f"DEBUG: Found title in retrieved_context: {retrieved_context.title}")
                
                # uriã‚’å–å¾—
                if hasattr(retrieved_context, 'uri') and retrieved_context.uri:
                    chunk_dict['uri'] = retrieved_context.uri
                    print(f"DEBUG: Found uri in retrieved_context: {retrieved_context.uri}")
            
            # webãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ã‚‚ç¢ºèªï¼ˆå¿µã®ãŸã‚ï¼‰
            if hasattr(chunk, 'web') and chunk.web:
                print(f"DEBUG: Found web property: {chunk.web}")
                if not chunk_dict.get('title') and hasattr(chunk.web, 'title'):
                    chunk_dict['title'] = chunk.web.title
                if not chunk_dict.get('uri') and hasattr(chunk.web, 'uri'):
                    chunk_dict['uri'] = chunk.web.uri
            
            # ç›´æ¥çš„ãªtitle/uriãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ã‚‚ç¢ºèª
            if not chunk_dict.get('title') and hasattr(chunk, 'title'):
                chunk_dict['title'] = chunk.title
                print(f"DEBUG: Found direct title: {chunk.title}")
            if not chunk_dict.get('uri') and hasattr(chunk, 'uri'):
                chunk_dict['uri'] = chunk.uri
                print(f"DEBUG: Found direct uri: {chunk.uri}")
            
            # æ—¥ä»˜æƒ…å ±ã‚’æŠ½å‡ºã—ã¦ãƒ‡ãƒãƒƒã‚°å‡ºåŠ›
            if chunk_dict.get('title'):
                extracted_date = extract_date_from_filename(chunk_dict['title'])
                if extracted_date:
                    print(f"DEBUG: Extracted date from title '{chunk_dict['title']}': {extracted_date.strftime('%Y-%m-%d')}")
                else:
                    print(f"DEBUG: No date found in title '{chunk_dict['title']}'")
            
            unsorted_chunks.append(chunk_dict)
        
        # æ—¥ä»˜é †ã«ã‚½ãƒ¼ãƒˆï¼ˆæ–°ã—ã„æ—¥ä»˜ã‚’å„ªå…ˆï¼‰
        sorted_chunks = sort_sources_by_date(unsorted_chunks)
        result['grounding_chunks'] = sorted_chunks
        
        print(f"DEBUG: Sorted chunks by date:")
        for i, chunk in enumerate(sorted_chunks):
            title = chunk.get('title', 'ã‚¿ã‚¤ãƒˆãƒ«ãªã—')
            date = extract_date_from_filename(title)
            date_str = date.strftime('%Y-%m-%d') if date else 'æ—¥ä»˜ãªã—'
            print(f"  {i+1}. {title} ({date_str})")
        
    else:
        print("DEBUG: No grounding_chunks found")
    
    print(f"DEBUG: Final result: {result}")
    return result

def generate_plan_and_questions(user_message):
    """ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã‹ã‚‰è¨ˆç”»ã¨é–¢é€£è³ªå•ã‚’ç”Ÿæˆ"""
    try:
        client = create_rag_client()
        
        planning_prompt = f"""
ä»¥ä¸‹ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«å¯¾ã—ã¦ã€åŒ…æ‹¬çš„ã§è©³ç´°ãªå›ç­”ã‚’æä¾›ã™ã‚‹ãŸã‚ã®è¨ˆç”»ã‚’ç«‹ã¦ã¦ãã ã•ã„ã€‚

ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•: {user_message}

ä»¥ä¸‹ã®å½¢å¼ã§å›ç­”ã—ã¦ãã ã•ã„ï¼š

## èª¿æŸ»è¨ˆç”»
[ã“ã®è³ªå•ã«ç­”ãˆã‚‹ãŸã‚ã®èª¿æŸ»è¨ˆç”»ã‚’ç°¡æ½”ã«èª¬æ˜]

## é–¢é€£è³ªå•ãƒªã‚¹ãƒˆ
1. [é–¢é€£è³ªå•1]
2. [é–¢é€£è³ªå•2]
3. [é–¢é€£è³ªå•3]
4. [é–¢é€£è³ªå•4]
5. [é–¢é€£è³ªå•5]

é–¢é€£è³ªå•ã¯ä»¥ä¸‹ã®è¦³ç‚¹ã‹ã‚‰ä½œæˆã—ã¦ãã ã•ã„ï¼š
- åŸºæœ¬çš„ãªå®šç¾©ã‚„æ¦‚å¿µ
- å…·ä½“çš„ãªäº‹ä¾‹ã‚„å¿œç”¨
- ãƒ¡ãƒªãƒƒãƒˆãƒ»ãƒ‡ãƒ¡ãƒªãƒƒãƒˆ
- æœ€æ–°ã®å‹•å‘ã‚„èª²é¡Œ
- é–¢é€£ã™ã‚‹æŠ€è¡“ã‚„æ‰‹æ³•

å„è³ªå•ã¯ç‹¬ç«‹ã—ã¦å›ç­”å¯èƒ½ã§ã€å…ƒã®è³ªå•ã®ç†è§£ã‚’æ·±ã‚ã‚‹ã‚‚ã®ã«ã—ã¦ãã ã•ã„ã€‚
"""
        
        contents = [
            types.Content(
                role="user",
                parts=[types.Part(text=planning_prompt)]
            )
        ]
        
        config = types.GenerateContentConfig(
            temperature=0.7,
            top_p=0.9,
            max_output_tokens=1000,
        )
        
        response = client.models.generate_content(
            model=GEMINI_MODEL,
            contents=contents,
            config=config,
        )
        
        if response and response.text:
            return response.text
        else:
            print("WARNING: Empty response from planning model")
            return f"""
## èª¿æŸ»è¨ˆç”»
{user_message}ã«ã¤ã„ã¦è©³ç´°ã«èª¿æŸ»ã—ã¾ã™ã€‚

## é–¢é€£è³ªå•ãƒªã‚¹ãƒˆ
1. {user_message}ã®åŸºæœ¬çš„ãªå®šç¾©ã¨ã¯ä½•ã§ã™ã‹ï¼Ÿ
2. {user_message}ã®å…·ä½“çš„ãªäº‹ä¾‹ã‚’æ•™ãˆã¦ãã ã•ã„
3. {user_message}ã®ãƒ¡ãƒªãƒƒãƒˆã¨ãƒ‡ãƒ¡ãƒªãƒƒãƒˆã¯ä½•ã§ã™ã‹ï¼Ÿ
4. {user_message}ã®æœ€æ–°ã®å‹•å‘ã¯ã©ã†ã§ã™ã‹ï¼Ÿ
5. {user_message}ã«é–¢é€£ã™ã‚‹æŠ€è¡“ã‚„æ‰‹æ³•ã¯ã‚ã‚Šã¾ã™ã‹ï¼Ÿ
"""
    except Exception as e:
        print(f"Error in generate_plan_and_questions: {e}")
        return f"""
## èª¿æŸ»è¨ˆç”»
{user_message}ã«ã¤ã„ã¦è©³ç´°ã«èª¿æŸ»ã—ã¾ã™ã€‚

## é–¢é€£è³ªå•ãƒªã‚¹ãƒˆ
1. {user_message}ã®åŸºæœ¬çš„ãªå®šç¾©ã¨ã¯ä½•ã§ã™ã‹ï¼Ÿ
2. {user_message}ã®å…·ä½“çš„ãªäº‹ä¾‹ã‚’æ•™ãˆã¦ãã ã•ã„
3. {user_message}ã®ãƒ¡ãƒªãƒƒãƒˆã¨ãƒ‡ãƒ¡ãƒªãƒƒãƒˆã¯ä½•ã§ã™ã‹ï¼Ÿ
4. {user_message}ã®æœ€æ–°ã®å‹•å‘ã¯ã©ã†ã§ã™ã‹ï¼Ÿ
5. {user_message}ã«é–¢é€£ã™ã‚‹æŠ€è¡“ã‚„æ‰‹æ³•ã¯ã‚ã‚Šã¾ã™ã‹ï¼Ÿ
"""

def execute_single_rag_query(question):
    """å˜ä¸€ã®RAGã‚¯ã‚¨ãƒªã‚’å®Ÿè¡Œ"""
    try:
        client = create_rag_client()
        
        contents = [
            types.Content(
                role="user",
                parts=[types.Part(text=question)]
            )
        ]
        
        tools = [
            types.Tool(
                retrieval=types.Retrieval(
                    vertex_rag_store=types.VertexRagStore(
                        rag_resources=[
                            types.VertexRagStoreRagResource(
                                rag_corpus=RAG_CORPUS
                            )
                        ],
                    )
                )
            )
        ]

        config = types.GenerateContentConfig(
            temperature=0.8,
            top_p=0.9,
            max_output_tokens=2000,
            tools=tools,
        )
        
        response = client.models.generate_content(
            model=GEMINI_MODEL,
            contents=contents,
            config=config,
        )
        
        # ã‚°ãƒ©ã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        grounding_metadata = None
        if hasattr(response, 'candidates') and response.candidates:
            candidate = response.candidates[0]
            if hasattr(candidate, 'grounding_metadata') and candidate.grounding_metadata:
                grounding_metadata = candidate.grounding_metadata
        
        answer_text = response.text if response and response.text else "å›ç­”ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚"
        return answer_text, grounding_metadata
        
    except Exception as e:
        print(f"Error in execute_single_rag_query: {e}")
        return f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}", None

def synthesize_comprehensive_answer(user_message, plan_text, qa_results):
    """è¨ˆç”»ã¨å„è³ªå•ã®å›ç­”ã‚’çµ±åˆã—ã¦åŒ…æ‹¬çš„ãªå›ç­”ã‚’ç”Ÿæˆ"""
    client = create_rag_client()
    
    qa_text = "\n\n".join([f"**Q: {q}**\nA: {a}" for q, a in qa_results])
    
    synthesis_prompt = f"""
ä»¥ä¸‹ã®æƒ…å ±ã‚’åŸºã«ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«å¯¾ã™ã‚‹åŒ…æ‹¬çš„ã§è©³ç´°ãªå›ç­”ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

å…ƒã®è³ªå•: {user_message}

èª¿æŸ»è¨ˆç”»:
{plan_text}

é–¢é€£è³ªå•ã¨å›ç­”:
{qa_text}

ä»¥ä¸‹ã®è¦ä»¶ã«å¾“ã£ã¦å›ç­”ã‚’ä½œæˆã—ã¦ãã ã•ã„ï¼š
1. å…ƒã®è³ªå•ã«ç›´æ¥ç­”ãˆã‚‹
2. é–¢é€£è³ªå•ã®å›ç­”ã‹ã‚‰å¾—ã‚‰ã‚ŒãŸæƒ…å ±ã‚’çµ±åˆã™ã‚‹
3. è«–ç†çš„ã§èª­ã¿ã‚„ã™ã„æ§‹æˆã«ã™ã‚‹
4. é‡è¦ãªãƒã‚¤ãƒ³ãƒˆã‚’å¼·èª¿ã™ã‚‹
5. å…·ä½“ä¾‹ãŒã‚ã‚Œã°å«ã‚ã‚‹
6. Markdownå½¢å¼ã§æ•´ç†ã™ã‚‹

å›ç­”ã¯ä»¥ä¸‹ã®æ§‹æˆã‚’å‚è€ƒã«ã—ã¦ãã ã•ã„ï¼š
- æ¦‚è¦ãƒ»å®šç¾©
- è©³ç´°èª¬æ˜
- å…·ä½“ä¾‹ãƒ»äº‹ä¾‹
- ãƒ¡ãƒªãƒƒãƒˆãƒ»ãƒ‡ãƒ¡ãƒªãƒƒãƒˆ
- æœ€æ–°å‹•å‘ãƒ»èª²é¡Œ
- ã¾ã¨ã‚
"""
    
    contents = [
        types.Content(
            role="user",
            parts=[types.Part(text=synthesis_prompt)]
        )
    ]
    
    config = types.GenerateContentConfig(
        temperature=0.7,
        top_p=0.9,
        max_output_tokens=4000,
    )
    
    response = client.models.generate_content(
        model=GEMINI_MODEL,
        contents=contents,
        config=config,
    )
    
    return response.text

def generate_deep_response(user_message):
    """æ·±æ˜ã‚Šæ©Ÿèƒ½ä»˜ãã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ç”Ÿæˆ"""
    try:
        # ã‚¹ãƒ†ãƒƒãƒ—1: è¨ˆç”»ç«‹ã¦ã¨é–¢é€£è³ªå•ç”Ÿæˆ
        yield {
            'chunk': '\n## ğŸ“‹ èª¿æŸ»è¨ˆç”»ã‚’ç«‹æ¡ˆä¸­...\n',
            'done': False,
            'grounding_metadata': None,
            'step': 'planning'
        }
        
        plan_text = generate_plan_and_questions(user_message)
        
        if not plan_text:
            plan_text = f"""
## èª¿æŸ»è¨ˆç”»
{user_message}ã«ã¤ã„ã¦è©³ç´°ã«èª¿æŸ»ã—ã¾ã™ã€‚

## é–¢é€£è³ªå•ãƒªã‚¹ãƒˆ
1. {user_message}ã®åŸºæœ¬çš„ãªå®šç¾©ã¨ã¯ä½•ã§ã™ã‹ï¼Ÿ
2. {user_message}ã®å…·ä½“çš„ãªäº‹ä¾‹ã‚’æ•™ãˆã¦ãã ã•ã„
3. {user_message}ã®ãƒ¡ãƒªãƒƒãƒˆã¨ãƒ‡ãƒ¡ãƒªãƒƒãƒˆã¯ä½•ã§ã™ã‹ï¼Ÿ
4. {user_message}ã®æœ€æ–°ã®å‹•å‘ã¯ã©ã†ã§ã™ã‹ï¼Ÿ
5. {user_message}ã«é–¢é€£ã™ã‚‹æŠ€è¡“ã‚„æ‰‹æ³•ã¯ã‚ã‚Šã¾ã™ã‹ï¼Ÿ
"""
        
        yield {
            'chunk': f'\n{plan_text}\n\n## ğŸ” è©³ç´°èª¿æŸ»ã‚’é–‹å§‹...\n',
            'done': False,
            'grounding_metadata': None,
            'step': 'plan_complete'
        }
        
        # é–¢é€£è³ªå•ã‚’æŠ½å‡º
        questions = []
        try:
            lines = plan_text.split('\n')
            in_questions_section = False
            
            for line in lines:
                if 'é–¢é€£è³ªå•' in line:
                    in_questions_section = True
                    continue
                if in_questions_section and line.strip():
                    if line.strip().startswith(('1.', '2.', '3.', '4.', '5.')):
                        question = line.strip()[2:].strip()
                        if question and question not in questions:
                            questions.append(question)
        except Exception as e:
            print(f"Error extracting questions: {e}")
            questions = [
                f"{user_message}ã®åŸºæœ¬çš„ãªå®šç¾©ã¨ã¯ä½•ã§ã™ã‹ï¼Ÿ",
                f"{user_message}ã®å…·ä½“çš„ãªäº‹ä¾‹ã‚’æ•™ãˆã¦ãã ã•ã„",
                f"{user_message}ã®ãƒ¡ãƒªãƒƒãƒˆã¨ãƒ‡ãƒ¡ãƒªãƒƒãƒˆã¯ä½•ã§ã™ã‹ï¼Ÿ",
                f"{user_message}ã®æœ€æ–°ã®å‹•å‘ã¯ã©ã†ã§ã™ã‹ï¼Ÿ",
                f"{user_message}ã«é–¢é€£ã™ã‚‹æŠ€è¡“ã‚„æ‰‹æ³•ã¯ã‚ã‚Šã¾ã™ã‹ï¼Ÿ"
            ]
        
        # è³ªå•ãŒå°‘ãªã„å ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        if len(questions) < 3:
            questions = [
                f"{user_message}ã®åŸºæœ¬çš„ãªå®šç¾©ã¨ã¯ä½•ã§ã™ã‹ï¼Ÿ",
                f"{user_message}ã®å…·ä½“çš„ãªäº‹ä¾‹ã‚’æ•™ãˆã¦ãã ã•ã„",
                f"{user_message}ã®ãƒ¡ãƒªãƒƒãƒˆã¨ãƒ‡ãƒ¡ãƒªãƒƒãƒˆã¯ä½•ã§ã™ã‹ï¼Ÿ",
                f"{user_message}ã®æœ€æ–°ã®å‹•å‘ã¯ã©ã†ã§ã™ã‹ï¼Ÿ",
                f"{user_message}ã«é–¢é€£ã™ã‚‹æŠ€è¡“ã‚„æ‰‹æ³•ã¯ã‚ã‚Šã¾ã™ã‹ï¼Ÿ"
            ]
        
        # ã‚¹ãƒ†ãƒƒãƒ—2: å„é–¢é€£è³ªå•ã‚’é †æ¬¡å®Ÿè¡Œ
        qa_results = []
        all_grounding_metadata = []
        all_unique_sources = {}  # é‡è¤‡ã‚’é¿ã‘ã‚‹ãŸã‚è¾æ›¸ã§ç®¡ç†
        
        for i, question in enumerate(questions[:5], 1):
            yield {
                'chunk': f'\n### ğŸ” è³ªå• {i}: {question}\nèª¿æŸ»ä¸­...\n',
                'done': False,
                'grounding_metadata': None,
                'step': f'query_{i}'
            }
            
            answer, grounding_metadata = execute_single_rag_query(question)
            qa_results.append((question, answer))
            
            # å‡ºå…¸æƒ…å ±ã‚’å‡¦ç†
            converted_metadata = None
            if grounding_metadata:
                all_grounding_metadata.append(grounding_metadata)
                converted_metadata = convert_grounding_metadata_to_dict(grounding_metadata)
                
                # å‡ºå…¸æƒ…å ±ã‚’çµ±åˆï¼ˆé‡è¤‡ã‚’é¿ã‘ã‚‹ï¼‰
                if converted_metadata and 'grounding_chunks' in converted_metadata:
                    for chunk in converted_metadata['grounding_chunks']:
                        if chunk.get('uri'):
                            all_unique_sources[chunk['uri']] = {
                                'title': chunk.get('title', 'ã‚¿ã‚¤ãƒˆãƒ«ãªã—'),
                                'uri': chunk['uri']
                            }
            
            # å›ç­”ã‚’é€ä¿¡
            yield {
                'chunk': f'\n**ğŸ’¡ å›ç­” {i}:** {answer}\n',
                'done': False,
                'grounding_metadata': converted_metadata,
                'step': f'answer_{i}'
            }
            
            # å„è³ªå•ã®å‡ºå…¸æƒ…å ±ã‚’å€‹åˆ¥ã«è¡¨ç¤º
            if converted_metadata and 'grounding_chunks' in converted_metadata:
                # å‡ºå…¸æƒ…å ±ã‚’æ—¥ä»˜é †ã«ã‚½ãƒ¼ãƒˆ
                sorted_chunks = sort_sources_by_date(converted_metadata['grounding_chunks'])
                
                sources_text = '\n**ğŸ“š ã“ã®å›ç­”ã®å‡ºå…¸:**\n'
                for j, chunk in enumerate(sorted_chunks, 1):
                    title = chunk.get('title', 'ã‚¿ã‚¤ãƒˆãƒ«ãªã—')
                    uri = chunk.get('uri', '')
                    
                    # æ—¥ä»˜æƒ…å ±ã‚’è¡¨ç¤ºã«å«ã‚ã‚‹
                    extracted_date = extract_date_from_filename(title)
                    date_info = f" ({extracted_date.strftime('%Y-%m-%d')})" if extracted_date else ""
                    
                    sources_text += f'   {j}. {title}{date_info}\n'
                    if uri:
                        sources_text += f'      ğŸ“ {uri}\n'
                sources_text += '\n'
                
                yield {
                    'chunk': sources_text,
                    'done': False,
                    'grounding_metadata': None,
                    'step': f'sources_{i}'
                }
        
        # ã‚¹ãƒ†ãƒƒãƒ—3: åŒ…æ‹¬çš„ãªå›ç­”ã®çµ±åˆ
        yield {
            'chunk': '\n## ğŸ“ åŒ…æ‹¬çš„ãªå›ç­”ã‚’ä½œæˆä¸­...\n',
            'done': False,
            'grounding_metadata': None,
            'step': 'synthesizing'
        }
        
        comprehensive_answer = synthesize_comprehensive_answer(user_message, plan_text, qa_results)
        
        yield {
            'chunk': f'\n## ğŸ¯ åŒ…æ‹¬çš„ãªå›ç­”\n\n{comprehensive_answer}\n',
            'done': False,
            'grounding_metadata': None,
            'step': 'synthesis_complete'
        }
        
        # å…¨ã¦ã®å‡ºå…¸æƒ…å ±ã‚’çµ±åˆã—ã¦è¡¨ç¤º
        if all_unique_sources:
            # æ—¥ä»˜é †ã«ã‚½ãƒ¼ãƒˆã—ã¦ã‹ã‚‰è¡¨ç¤º
            sorted_unique_sources = sort_sources_by_date(list(all_unique_sources.values()))
            
            yield {
                'chunk': '\n## ğŸ“š å…¨ä½“ã®å‡ºå…¸æƒ…å ±\n\n',
                'done': False,
                'grounding_metadata': None,
                'step': 'all_sources_header'
            }
            
            sources_summary = ''
            for i, source_info in enumerate(sorted_unique_sources, 1):
                title = source_info.get('title', 'ã‚¿ã‚¤ãƒˆãƒ«ãªã—')
                uri = source_info.get('uri', '')
                
                # æ—¥ä»˜æƒ…å ±ã‚’è¡¨ç¤ºã«å«ã‚ã‚‹
                extracted_date = extract_date_from_filename(title)
                date_info = f" ({extracted_date.strftime('%Y-%m-%d')})" if extracted_date else ""
                
                sources_summary += f'**{i}. {title}{date_info}**\n'
                sources_summary += f'   ğŸ“ {uri}\n\n'
            
            yield {
                'chunk': sources_summary,
                'done': False,
                'grounding_metadata': None,
                'step': 'all_sources_list'
            }
        
        # æœ€çµ‚çš„ãªå‡ºå…¸æƒ…å ±ã‚’çµ±åˆï¼ˆJSONã¨ã—ã¦é€ä¿¡ï¼‰
        final_grounding_metadata = None
        if all_grounding_metadata:
            # å…¨ã¦ã®å‡ºå…¸æƒ…å ±ã‚’çµ±åˆã—ã€æ—¥ä»˜é †ã«ã‚½ãƒ¼ãƒˆ
            sorted_unique_sources = sort_sources_by_date(list(all_unique_sources.values()))
            final_grounding_metadata = {
                'grounding_chunks': sorted_unique_sources
            }
        
        yield {
            'chunk': '',
            'done': True,
            'grounding_metadata': final_grounding_metadata,
            'step': 'complete'
        }
        
    except Exception as e:
        print(f"Deep response generation error: {e}")
        yield {
            'chunk': f'\nâŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}\né€šå¸¸ãƒ¢ãƒ¼ãƒ‰ã§å›ç­”ã‚’è©¦ã¿ã¾ã™...\n',
            'done': False,
            'grounding_metadata': None,
            'step': 'error'
        }
        
        # ã‚¨ãƒ©ãƒ¼æ™‚ã¯é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        try:
            for chunk_data in generate_response(user_message):
                yield chunk_data
        except Exception as fallback_error:
            print(f"Fallback error: {fallback_error}")
            yield {
                'chunk': f'\nâŒ å›ç­”ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ: {str(fallback_error)}\n',
                'done': True,
                'grounding_metadata': None,
                'step': 'fallback_error'
            }

def generate_response(user_message):
    """ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«å¯¾ã—ã¦RAGã‚’ä½¿ç”¨ã—ã¦ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ç”Ÿæˆ"""
    client = create_rag_client()
    
    contents = [
        types.Content(
            role="user",
            parts=[
                types.Part(text=user_message)
            ]
        )
    ]
    tools = [
        types.Tool(
            retrieval=types.Retrieval(
                vertex_rag_store=types.VertexRagStore(
                    rag_resources=[
                        types.VertexRagStoreRagResource(
                            rag_corpus=RAG_CORPUS
                        )
                    ],
                )
            )
        )
    ]

    # GenerateContentConfigã‚’ä½œæˆ
    config_params = {
        'temperature': 1,
        'top_p': 1,
        'seed': 0,
        'max_output_tokens': 65535,
        'safety_settings': [
            types.SafetySetting(
                category="HARM_CATEGORY_HATE_SPEECH",
                threshold="OFF"
            ),
            types.SafetySetting(
                category="HARM_CATEGORY_DANGEROUS_CONTENT",
                threshold="OFF"
            ),
            types.SafetySetting(
                category="HARM_CATEGORY_SEXUALLY_EXPLICIT",
                threshold="OFF"
            ),
            types.SafetySetting(
                category="HARM_CATEGORY_HARASSMENT",
                threshold="OFF"
            )
        ],
        'tools': tools,
    }
    
    # ThinkingConfigãŒåˆ©ç”¨å¯èƒ½ãªå ´åˆã®ã¿è¿½åŠ 
    try:
        if hasattr(types, 'ThinkingConfig'):
            config_params['thinking_config'] = types.ThinkingConfig(
                thinking_budget=-1,
            )
    except AttributeError:
        pass  # ThinkingConfigãŒåˆ©ç”¨ã§ããªã„å ´åˆã¯ç„¡è¦–
    
    generate_content_config = types.GenerateContentConfig(**config_params)

    full_response = ""
    grounding_metadata = None
    
    print(f"DEBUG: Starting generation for message: {user_message}")
    
    for chunk in client.models.generate_content_stream(
        model=GEMINI_MODEL,
        contents=contents,
        config=generate_content_config,
    ):
        print(f"DEBUG: Raw chunk: {chunk}")
        
        if not chunk.candidates or not chunk.candidates[0].content or not chunk.candidates[0].content.parts:
            print("DEBUG: Skipping chunk - no content")
            continue
        
        print(f"DEBUG: Chunk type: {type(chunk)}")
        print(f"DEBUG: Chunk attributes: {[attr for attr in dir(chunk) if not attr.startswith('_')]}")
        
        # ãƒ†ã‚­ã‚¹ãƒˆã‚’è“„ç©
        full_response += chunk.text
        print(f"DEBUG: Added text: {chunk.text[:100]}...")
        
        # å…¨ã¦ã®å¯èƒ½ãªå ´æ‰€ã§ã‚°ãƒ©ã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’æ¢ã™
        candidate = chunk.candidates[0]
        print(f"DEBUG: Candidate attributes: {[attr for attr in dir(candidate) if not attr.startswith('_')]}")
        
        # å€™è£œ1: candidate.grounding_metadata
        if hasattr(candidate, 'grounding_metadata'):
            print(f"DEBUG: candidate.grounding_metadata exists: {candidate.grounding_metadata}")
            if candidate.grounding_metadata:
                print("DEBUG: Found grounding_metadata in candidate")
                grounding_metadata = candidate.grounding_metadata
        
        # å€™è£œ2: chunk.grounding_metadata
        if hasattr(chunk, 'grounding_metadata'):
            print(f"DEBUG: chunk.grounding_metadata exists: {chunk.grounding_metadata}")
            if chunk.grounding_metadata:
                print("DEBUG: Found grounding_metadata in chunk")
                grounding_metadata = chunk.grounding_metadata
            
        # å€™è£œ3: candidate.content.grounding_metadata
        if hasattr(candidate.content, 'grounding_metadata'):
            print(f"DEBUG: candidate.content.grounding_metadata exists: {candidate.content.grounding_metadata}")
            if candidate.content.grounding_metadata:
                print("DEBUG: Found grounding_metadata in candidate.content")
                grounding_metadata = candidate.content.grounding_metadata
        
        # å€™è£œ4: å…¨ä½“ã®æ§‹é€ ã‚’ç¢ºèª
        print(f"DEBUG: Full candidate structure:")
        for attr in dir(candidate):
            if not attr.startswith('_'):
                try:
                    value = getattr(candidate, attr)
                    print(f"  {attr}: {type(value)} - {value}")
                except:
                    print(f"  {attr}: <error accessing>")
        
        yield {
            'chunk': chunk.text,
            'done': False,
            'grounding_metadata': None
        }
    
    print(f"DEBUG: Final grounding_metadata: {grounding_metadata}")
    
    # æœ€å¾Œã«å‡ºå…¸æƒ…å ±ã‚’é€ä¿¡ï¼ˆè¾æ›¸å½¢å¼ã«å¤‰æ›ï¼‰
    converted_metadata = convert_grounding_metadata_to_dict(grounding_metadata)
    print(f"DEBUG: Converted metadata: {converted_metadata}")
    
    yield {
        'chunk': '',
        'done': True,
        'grounding_metadata': converted_metadata
    }

@app.route('/')
def index():
    """ãƒ¡ã‚¤ãƒ³ãƒšãƒ¼ã‚¸"""
    return render_template('index.html')

@app.route('/chat', methods=['POST'])
def chat():
    """ãƒãƒ£ãƒƒãƒˆã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""
    data = request.json
    user_message = data.get('message', '')
    use_deep_mode = data.get('deep_mode', False)
    
    if not user_message:
        return jsonify({'error': 'ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒç©ºã§ã™'}), 400
    
    def generate():
        try:
            if use_deep_mode:
                # æ·±æ˜ã‚Šãƒ¢ãƒ¼ãƒ‰ã‚’ä½¿ç”¨
                for chunk_data in generate_deep_response(user_message):
                    yield f"data: {json.dumps(chunk_data, ensure_ascii=False)}\n\n"
            else:
                # é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ã‚’ä½¿ç”¨
                for chunk_data in generate_response(user_message):
                    yield f"data: {json.dumps(chunk_data, ensure_ascii=False)}\n\n"
        except Exception as e:
            print(f"Error in chat endpoint: {e}")
            error_data = {
                'chunk': f'ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}',
                'done': True,
                'grounding_metadata': None
            }
            yield f"data: {json.dumps(error_data, ensure_ascii=False)}\n\n"
    
    return Response(generate(), mimetype='text/plain')

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=8080, debug=True) 